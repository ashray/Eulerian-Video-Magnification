{"name":"Eulerian-video-magnification","tagline":"Implement the Eulerian Video Magnification technique","body":"### Personal Details\r\n\r\nName: Ashray Malhotra\r\n\r\n\r\nUniversity: [Indian Institute of Technology, Bombay](http://www.iitb.ac.in)\r\n\r\n\r\nEmail: ashray.malhotra.1994@gmail.com\r\n\r\n\r\nTelephone: +91-9757163031\r\n\r\n\r\nCountry of Residence: India\r\n\r\n\r\nTimezone: IST (GMT + 0530)\r\n\r\n\r\nPrimary Language: English\r\n\r\n\r\nI am a fourth year dual degree student pursuing B.Tech. + M.Tech. in Electrical Engineering(specialisation in Signal Processing) at Indian Institute of Technology, Bombay. My semester will complete in late April leaving me enough time to get ready for my GSoC project. If I am selected, I shall be able to work around 40 hrs a week on the project, though am open to putting in more effort if the work requires.\r\n\r\n\r\n### Why this project?\r\n\r\nThis technique of motion magnification unlocks completely new avenues like detection of blood vessels,magnify motions of small babies etc. I look at this technology from the perspective of enabling a whole new dimension of use cases. So our aim should be to provide it to users/developers in as flexible form as possible so that people can build upon it for their personal use cases that they can think of. Obviously one of the use cases\r\n\r\n\r\nAnother advantage of this technique is that it can work in near real time. Hence it unlocks completely new avenues for technology.\r\n\r\n\r\n### Technical Knowledge\r\n\r\nI am a 4th year dual degree student in IIT Bombay. I am enrolled in a 5 year B.Tech. + M.Tech. course. My major is Electrical Engineering(it's more of maths and electronics though). My specialisation is in the field of Communications and Signal Processing. The courses that I have done include\r\n\r\n* Digital Signal Processing\r\n\r\n* [Fundamentals of Digital Image Processing](http://www.cse.iitb.ac.in/~ajitvr/CS663_Fall2014/)\r\n\r\n* Advanced Computing for Electrical Engineers(A compressed version of important CS contents)\r\n\r\n* Advanced Topics in Signal Processing\r\n\r\n* [Computer Vision](http://www.cse.iitb.ac.in/~ajitvr/CS763_Spring2015/)\r\n\r\n* [Algorithms for Medical Image Processing](http://www.cse.iitb.ac.in/~suyash/cs736/)\r\n\r\n\r\nI have done multiple [algorithms](https://www.coursera.org/course/algo) and [machine learning](https://www.coursera.org/course/ml) courses on coursera.\r\n\r\n\r\nSome of my previous projects in image processing and computer vision include - \r\n\r\n* Video Stabilisation using RANSAC and least squares features\r\n\r\n* Denoising MRI images\r\n\r\n* Digit Recognition on [MNIST database](http://yann.lecun.com/exdb/mnist/). Achieved nearly 91% accuracy with a 100 dimensional subspace(for images of size 28*28 = 784) using PCA technique. Implemented LDA(Fisher's LDA) and ICA techniques.\r\n\r\n\r\nSome of my signal processing projects include -\r\n\r\n* Source localisation\r\n\r\n* Audio Source Seperation\r\n\r\n* Speech Recognition System\r\n\r\n\r\nAm currently working on many interesting projects, including Iris detection, finding out innovative techniques for improving temporal resolution of a signal(research project with [Prof Subhasis Chaudhuri](https://scholar.google.co.in/citations?user=84VkdegAAAAJ&hl=en&oi=ao)) etc. Am also currently working on implementing the video magnification algorithm. Read ahead in the personal motivation section for the reasons why I have already been working on implementing this technique.\r\n\r\n\r\nI interned with Goldman Sachs technologies in my third year. My work involved extensive use of Java. Goldman involved working with teams across the globe. So I am comfortable working with people across multiple time zones and this shall not be a problem in the development process. I have worked with C++ in my advanced computing course. Based on my skills, I was selected to be a Teaching Assistant for [IIT Bombay's first online course](https://www.edx.org/course/introduction-computer-programming-part-1-iitbombayx-cs101-1x), in which programming was taught in C++.\r\n\r\n\r\nProgramming languages I have previously worked with include C++, Java, Cilk, Python, Matlab, openGL, CUDA, Assembly Language Programming, etc.\r\n\r\n\r\n## Project\r\n\r\n\r\n### Project Abstract\r\n\r\nThis project aims to develop algorithms to extract out subtle changes in a time-dependent data set and amplify them. To begin with, the data set can be considered as videos(2D data at each temporal resolution) but scope of the project can be modified to deal with different dimensional datasets at each time instant.\r\n\r\n\r\n## Technical Details\r\nBelow we have explained the significant steps of the algorithm.\r\n* We start by considering each of the frame of the video independently for analysis\r\n* We choose a suitable colour space in which we want to work, This could depend on the specific application that we are dealing with, though in the paper, authors have used NTSC color space for further operations. \r\n```\r\nframe = rgb2ntsc(rgbframe);\r\n```\r\n\r\n* For each of the color level(or spectrum level for hyper spectral images), we build a Laplacian pyramid. Note the Laplacian Pyramid is built of the NTSC image, not the RGB image.\r\n```\r\n[pyr,pind] = buildLaplacianPyramid(frame(:,:,1))\r\n```\r\n* We initialise the lowpass filter to have the Laplacian Pyramid values. Later, we will change the values of the filter limits to perform temporal filtering of the signal.\r\n* We consider the next frame, and perform the similar laplacian pyramid calculation on it(after converting in NTSC colour space).\r\n* The value of laplacian pyramids of subsequent frames is used to perform the temporal filtering of the signal. The exact method of temporal filtering could vary with application, for ex. we could use a butterworth filter, an IIR filter etc. For an IIR filter, we perform a simple multiplicative update of  both the filter threshold\r\n```\r\nlowpass = (1-const_factor)*lowpass + const_factor*pyramid;\r\n```\r\n* The difference of the computed thresholds gives us the range of frequencies to work with(magnify or suppress, based on the laplacian pyramid level)\r\n```\r\nfiltered = (cutoff1 - cutoff2);\r\n```\r\n* Now we have performed the temporal selection of the signal. We will selectively perform the spatial magnification of the signal. Note that the equation that we will use to magnify the spatial frequencies(amount of magnification of a specific spatial frequency), can vary across different use cases, but in this paper, the authors have used linearly increasing magnification with spatial wavelengths with a specific threshold after which the magnification remains constant.\r\n![Magnification Curve](https://raw.githubusercontent.com/ashray/Eulerian-Video-Magnification/master/Magnification%20Curve%20Used%20in%20Paper.png)\r\n\r\n!!!!!Insert Figure of the curve from paper!!!!!\r\n* The above figure gives us the magnification value at each spatial wavelength level(which is given by the pyramid index). We multiply the filtered signal above by the appropriate multiplication(or magnification) factor to get the modified filter values. Note that we will have to do this for all the images in the pyramid.\r\n* Using these final filtered values, we again recreate the image frame from the new image pyramid.\r\n* We can also consider adding some chromatic aberration if we either want to mix the motion magnified signal and the original signal better(more homogeneously without weird colour artifacts) or we want to show a clear motion in the subsequent frames hence clearly separate the motion magnification and the frame(we can have a contrast between them). Which of the two cases happens will depend on the exact method(and value) of chromatic aberration. \r\n```\r\noutput(:,:,1) = output(:,:,1)*chromaticAttenuation1; //Red channel chromatic attenuation\r\noutput(:,:,2) = output(:,:,2)*chromaticAttenuation2; //Green channel chromatic attenuation\r\noutput(:,:,3) = output(:,:,3)*chromaticAttenuation3; //Blue channel chromatic attenuation\r\n```\r\n* So we finally have the magnified motion. But we need the magnified motion on the image. Hence we add this magnified motion to the original input frame to get the output frame which we will write back to the output video.\r\n```\r\noutput = frame + output;\r\n```\r\n## Practically observing outputs of the above algorithm\r\n\r\n### Personal Inspiration for the Project\r\n\r\nI am really excited to work on the idea o video magnification. I have been following that topic since really long, first came to know about it from their [TED talk](http://www.ted.com/talks/michael_rubinstein_see_invisible_motion_hear_silent_sounds_cool_creepy_we_can_t_decide?language=en), which inspired me to read their [research paper](http://people.csail.mit.edu/mrub/vidmag/#publications). I was also working in the week long [ReDX camp](https://mitredxcampjan2015.wordpress.com) conducted by MIT Media lab(conducted by Prof Ramesh Raskar). One of the projects in that lab was to find out the human arteries. I was shocked to find out that doctors still need to stop the blood flow and then find the arteries. According to some data that was collected during the workshop, it could take upto 7 minutes to find an infants(or older people’s) correct blood vessels; in a crucial operation, this could be lethal. The team in that week had come up with an IR device which would assist the RGB camera of the cellphone and using Augmented Reality would superimpose the blood vessels(visible in IR) on to the RGB smartphone camera.\r\n\r\n\r\nBut I still had a problem with this solution, that we would still need a separate hardware, it could not be user friendly etc. So I wanted to apply the concept of Video Magnification to be able to magnify the blood vessel movement. This way, the injections could be correct in the first attempt and in no time.\r\n\r\n\r\nSo all of this was on back of my mind, churning, but my final push came from my personal experience. My grandfather had died a year ago, and when he had been taken to the hospital, the needles and stuff would pain him so much that he died in a lot of pain. From the horrible experience we had with him, my grandmother, who expired just a few months ago, was not even taken to the hospital and she died very calmly in the house. To me, this was a shock, because even in this era if people believe that hospitals actually make people’s life worse, then whats the entire point of health technology.\r\n\r\n\r\nWe all know that video magnification can solve this simple problem, the only issue is that it seems no one has actually put in effort to get it to the people. When I came back from my home town after this incident, I decided to take this challenge on myself. I decided to implement this technology myself, out of interest and as a course project in my Medical Image Processing course. By April end(this year), I would have myself implemented this technique(which would mean I would completely know how this works, not just have a theoretical understanding). I will be free in summers and even in the final year(5th year), we just have a research project and a course or two. It is my aim to be able to get this technology in the hands of as many people as I possibly can. I already had plans to work on an implementation of this technology in these summer vacations. I would be glad if I could do this as a part of GSOC along with Kitware.\r\n\r\n\r\nI have a huge personal inspiration to get this technology out to the world, and you can be assured of my motivation to complete this project.","google":"UA-61169459-1","note":"Don't delete this file! It's used internally to help with page regeneration."}